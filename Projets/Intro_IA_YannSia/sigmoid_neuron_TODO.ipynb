{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "TMI8P3Rr6f22"
   },
   "source": [
    "Ceci est la deuxième partie de la deuxième séance Ens'IA!\n",
    "Ici nous (enfin vous surtout) allons recoder un **sigmoid neuron**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "qO21nyMQDc74"
   },
   "outputs": [],
   "source": [
    "#Quelques imports utiles pour la suite...\n",
    "import math\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "xWn39ERTX4CZ"
   },
   "source": [
    "**Petit rappel**\n",
    "\n",
    "La fonction *d'activation* sigmoid qu'on note ici $\\sigma$ est\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "et on a de plus $$\\sigma'(x) = \\sigma(x)(1-\\sigma(x))$$\n",
    "$$\\\\[0.2 cm]$$\n",
    "\n",
    "La fonction de *loss* est la suivante :\n",
    "$$L = \\frac{1}{n}\\sum_{i =1}^n(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "*$\\rightarrow$Comment calculer $\\frac{\\partial L}{\\partial \\omega_i}$ avec l'entrée $k$?*\n",
    "\n",
    "On note:  \n",
    "$$\n",
    "h_k = \\sum_{i=1}^{n} a_{i}^{k}*w_{i} + b \\\\\n",
    "y_k = \\sigma(h_k)\n",
    "$$\n",
    "\n",
    "On a avec la règle de la chaîne\n",
    "$$\\frac{\\partial L}{\\partial \\omega_i} = \\frac{\\partial L}{\\partial y_k} \\frac{\\partial y_k}{\\partial h_k}\\frac{\\partial h_k}{\\partial w_i}$$\n",
    "\n",
    "D'où\n",
    "$$\\frac{\\partial L}{\\partial \\omega_i} = -2(y_k - \\hat{y_k}) \\sigma'(h_k)a_{i}^k$$\n",
    "\n",
    "Pour simplifier les calculs lors de l'exécution de l'algorithme on notera:\n",
    "\n",
    "$$\\delta  = -2(y_k - \\hat{y_k})\\sigma'(h_k)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "gZvbMRo_DqpU"
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1 + math.exp(-x))\n",
    "assert(sigmoid(0)==0.5)\n",
    "sigmoid_derivative = lambda x: sigmoid(x)(1 - sigmoid(x))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "4-ZgyF4xDh5J"
   },
   "outputs": [],
   "source": [
    "class Neurone:\n",
    "\n",
    "    \"\"\"\n",
    "    Création d'un perceptron\n",
    "    Attributes:\n",
    "        weights (list): liste de weights\n",
    "        bias (int): le bias\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, entree):\n",
    "        \"\"\"Fonction appellée quand on veut obtenir la sortie à partir de l'entrée.\n",
    "\n",
    "        Parameters:\n",
    "            entree (list): les valeurs d'entrée\n",
    "\n",
    "        \"\"\"\n",
    "        assert(len(input) == len(self.weights))\n",
    "        return bool(sum([w*e for w, e in zip(self.weights, entree)]) + self.bias >= 0)\n",
    "\n",
    "    def delta(self, predicted_output, expected_output, entree):\n",
    "        \"\"\"Calcule le delta montré dans les formules au dessus.\"\"\"\n",
    "        list_hk = [sum([w*e for w, e in zip(self.weights, entree)]) for k in \n",
    "        return -2*()\n",
    "        \n",
    "\n",
    "    def backward(self, entree, delta):\n",
    "        \"\"\"Modifie les weights et les biais de le sens inverse de delta.\"\"\"\n",
    "        learning_rate = 0.1\n",
    "        #TODO\n",
    "\n",
    "    def accuracy(self, inputs, outputs):\n",
    "        \"\"\"Calcule l'accuracy du neurone.\n",
    "        \n",
    "        Parameters:\n",
    "            inputs (list): liste de liste d'inputs\n",
    "            outputs (list): liste de valeurs attendues en sortie\n",
    "        \"\"\"\n",
    "\n",
    "    def predict(self, entree):\n",
    "        \"\"\"A partir de l'input, retourne la valeur prédite (0 ou 1).\"\"\"\n",
    "        return int(round(self.forward(entree)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "ZKwTrsC067de"
   },
   "source": [
    "Maintenant que vous avez programmé un **sigmoid neuron**, vous allez pouvoir l'utiliser! Essayons de permettre à ce neurone d'**apprendre** à reproduire le comportement d'une porte OR.\n",
    "Cette fois-ci, plus besoin de chercher vous même les bons weights et biais. Ils vont être appris automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "cUsMUdNjDqRT"
   },
   "outputs": [],
   "source": [
    "#Exemple pour OR\n",
    "neurone_or = Neurone([randint(0,10),randint(0,10)], randint(0,5)) #On crée un neurone donc les weights et biais sont initialisés de manière aléatoire\n",
    "input_or = [[1,1], [1,0], [0,1], [0,0]] #liste des entrées possibles pour le neurone\n",
    "output_or = [1, 1, 1, 0] #liste de sorties attendues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "3-OTlGHN70p5"
   },
   "source": [
    "Maintenant que l'on a créé le neurone, il va falloir l'entraîner! Il va donc falloir faire une boucle qui entraine le neurone suffisamment pour qu'il puisse prédire toutes les sorties correctement. On apelle le nombre de fois que l'on va passer dans cette boucle, le nombre d'**epochs**. Une **epoch** correspond à un entrainement sur toutes les données. Faire 10 épochs revient donc à entrainer le neurone 10 fois sur les 4 données d'entrée.\n",
    "Pour chaque epoch il faut:\n",
    "\n",
    "1.   Faire passer les données dans le réseau de neurones\n",
    "2.   Calculer la loss\n",
    "3.   Backpropager la loss\n",
    "\n",
    "Afin de pouvoir suivre l'évolution de notre neurone, calculez, à chaque fin de boucle l'accuracy et enregistrez la quelque part. Vous pourrez ainsi tracer un graphe pour voir si l'accuracy de votre neurone augmente bien au cours du temps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "j-H4_IHIDxOG"
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "accuracy = []\n",
    "epochs_or =  #trouver un bon nombre d'epochs\n",
    "for j in range(epochs_or):\n",
    "  #TODO - entrainement\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "SWO3euAwvKPk"
   },
   "source": [
    "Si vous en êtes là, c'est que normalement vous avez entraîné un neurone à reproduire une porte OR! Vérifiez par vous même les sorties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "qcdPuK2aDzyW"
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "  print(\"Prédit : \"+str(neurone_or.predict(input_or[i]))+\" Vrai résultat : \"+str(output_or[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "KCFUU8GlvkR7"
   },
   "source": [
    "A l'aide de *plt.plot*, tracez une jolie courbe pour voir comment l'accuracy de votre modèle a évolué au cours du temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "upmWxqWEB36O"
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "p4WlTR6Ky0eG"
   },
   "source": [
    "\n",
    "Pour comprendre ce que fait exactement notre petit neurone, on va tracer sa ligne de décision.\n",
    "\n",
    "Cette ligne correspond au cas où $y = \\frac{1}{2}$ où y représente l'output pour un ($x_2$, $x_1$).\n",
    "\n",
    "$$ y = \\frac{1}{2} \\iff x_2w_2 + x_1w_1 + b = 0$$\n",
    "\n",
    "En écrivant ensuite $x_2$ selon $x_1$ cela revient à \n",
    "$$x_2 = \\frac{-x_1w_1 - b}{w_2}$$\n",
    "\n",
    "Pour tracer cette ligne de decision on doit donc tracer $f$ où $$f(x) = \\frac{-w_1x - b}{w_2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "CkArKaWjqQwh"
   },
   "outputs": [],
   "source": [
    "#On affiche les zones de décisions\n",
    "x = linspace(-0.1, 1.1, 30)\n",
    "#On trace f\n",
    "y = -neurone_or.weights[0] / neurone_or.weights[1] * x - neurone_or.bias / neurone_or.weights[1]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.scatter([0,1,1], [1,0,1], c = 'red')\n",
    "plt.scatter([0], [0], c = 'blue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "KgyOktw068cX"
   },
   "source": [
    "Et si vous tentiez maintenant d'entraîner un *neuron sigmoid* à reproduire le comportement d'une porte XOR...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "VfzoukL2D1lo"
   },
   "outputs": [],
   "source": [
    "#Exemple pour XOR \n",
    "neurone_xor = Neurone([randint(0,20),randint(0,20)], randint(-20,-15))\n",
    "input_xor = [[1,1], [1,0], [0,1], [0,0]]\n",
    "output_xor = [0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "XxUOR_wLD3wp"
   },
   "outputs": [],
   "source": [
    "#TODO - Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "fsPMCJDqD53k"
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "  print(\"Prédit : \"+str(neurone_xor.predict(input_or[i]))+\" Vrai résultat : \"+str(output_xor[i]))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "e-B6kgMBtBBy"
   },
   "outputs": [],
   "source": [
    "x = linspace(-0.1, 1.1, 30)\n",
    "y = - neurone_xor.weights[0] / neurone_xor.weights[1] * x - neurone_xor.bias / neurone_xor.weights[1]\n",
    "plt.plot(x, y)\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.scatter([0,1], [0,1], c = 'red')\n",
    "plt.scatter([0,1], [1,0], c = 'blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "Zj5hUns2Qbe-"
   },
   "outputs": [],
   "source": [
    "#TODO - accuracy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sigmoid_neuron_TODO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
