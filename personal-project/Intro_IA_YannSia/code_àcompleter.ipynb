{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_àcompleter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydf0BUawr40O",
        "colab_type": "text"
      },
      "source": [
        "**50 nuances d'IA : Introduction**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujkuK3eUG--r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import math  \n",
        "%matplotlib inline \n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data() #on charge le jeu de données"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvRbppLmtDPI",
        "colab_type": "text"
      },
      "source": [
        "Pour vous présenter les notions principales du Machine Learning, nous allons vous introduire deux algorithmes de base : KNN et K-MEAN.\n",
        "\n",
        "Ils seront appliqués au jeu de données CIFAR 10, jeu de données de 50 000 images appartenant à 10 classes d'images différentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg-w9JxkHUFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Observons les dimensions du jeu de données\n",
        "print(\"Images du jeu d'entrainement \"+str(x_train.shape));\n",
        "print(\"Classes du jeu d'entrainement \"+str(y_train.shape));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCPJCZpvsXLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisons un exemple et sa classe\n",
        "plt.imshow(x_train[0])\n",
        "plt.show()\n",
        "\n",
        "print(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoPPlTlmx29Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#visualisation du jeu de données\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "for y, cls in enumerate(classes):\n",
        "    idxs = np.flatnonzero(y_train == y)\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i * num_classes + y + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(x_train[idx].astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06RJZmTwurDx",
        "colab_type": "text"
      },
      "source": [
        "K-NN (K Nearest Neighbor ou méthode des K plus proches voisins) est un algorithme consistant à trouver, dans le jeu de données d'entrainement, les K images ressemblant le plus à l'image dont nous souhaitons trouver la classe. Pour calculer la ressemblance entre deux images on peut considérer simplement leur distance euclidienne (norme L2). Sur les K images trouvées, nous regarderons ensuite quelle classe est la plus présente. On pourra ainsi décider de la classe de notre image de test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVJ9wAKP-tA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nous redimensionons les images en les applatissant afin de faciliter leur manipulation\n",
        "x_train = x_train.reshape(50000,32*32*3)\n",
        "x_test = x_test.reshape(10000,32*32*3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxx7vRIk24SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Méthode brute --- Code d'un 1NN\n",
        "nearest = []\n",
        "for id_image, image in enumerate(x_test):\n",
        "  # On initialise les variables\n",
        "  min_d = None\n",
        "  min_k = None\n",
        "  for id_comp_image, comp_image in enumerate(x_train):\n",
        "    # On calcule la distance euclidienne entre les images (Norme euclidienne sur des dans R^n)\n",
        "    d = np.linalg.norm(image - comp_image)\n",
        "    if (min_d is None) or (d < min_d):\n",
        "      min_d = d\n",
        "      min_k = id_comp_image\n",
        "  print(y_train[min_k])\n",
        "  nearest.append(y_train[min_k])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTApXkk7reYd",
        "colab_type": "text"
      },
      "source": [
        "Cependant le code au dessus est pas très beau et le réimplémenter est un peu pénible.\n",
        "Afin de simplifier la vie de tout le monde, nous allons utiliser une bibliothèque du nom de **sickit learn**.\n",
        "Cette bibliothèque est une boite à outils remplie de beaucoup de fonctions très pratiques et d'algorithmes d'apprentissages prêts à l'utilisation. On vous laisse chercher [ici](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) comment l'utiliser\n",
        "**Nous vous déconseillons de faire l'entrainement sur les 50 000 éléments de x_train et le test sur les 10 000 éléments de x_test car cela vous prendrait trop de temps pour tester...**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfCuTLT29v-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier #on importe la bibliothèque\n",
        "#Regardez la fonction fit et la fonction score...\n",
        "#TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7vJQRnJzi4z",
        "colab_type": "text"
      },
      "source": [
        "La fonction score nous a permis de mesure la précision (accuracy) de l'algorithme KNN sur une partie de notre\n",
        "jeu de données.\n",
        "Nous avons obtenu 0.29 ce qui veut dire que sur les 100 images testées, seules 29% étaient correctes.\n",
        "De plus, vous avez pu remarquer que le temps d'exécution était plutôt long. Imaginez le temps que cela mettrait si l'on voulait tester l'intégralité de notre jeu de test\n",
        "qui avait 10 000 exemples....\n",
        "Ici, nous avons testé pour k = 7. Mais quelle est la valeur optimale de **k**? k est ce que l'on apelle un **hyperparamètre**. C'est une valeur à configurer avant l'entrainement de notre modèle sur le jeu de données.\n",
        "A vous de la trouver...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuF31W-_xNyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mettre ici le code de recherche du meilleur k\n",
        "#TODO\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fWSx-XOXBLa",
        "colab_type": "text"
      },
      "source": [
        "La méthode K-MEAN (ou méthode des K-moyennes) est un algorithme de partionnement de données (*clustering* en anglais). C'est l'un des algorithmes les plus fondamentaux en apprentissage non supervisé. L'algorithme consiste  à partionner des données pour tenter d'en dégager des classes. Dans notre cas, appliqué aux images de CIFAR-10, cela  revient a classer les images tel que cela est déjà fait mais en utilisant juste les données brutes (c'est pour cela que l'on parle d'apprentissage *non supervisé*). L'idée générale derrière la méthode est de regrouper les données en fonction de leurs ressemblances, i.e. de leur distance. L'algorithme fonctionne ainsi: on commence en considérant K données aléatoires, elles sont chacunes représentantes d'une classe ; à chaque itération, on va partionner les données en fonction de la ressemblance avec les K images types de départ : on regroupe dans la classe K toutes les images étant plus proches de la K-ème image type ; on calcule ensuite la moyenne des classes obtenues et l'on remplace l'image type de chacune des classes obtenues par cette moyenne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSnx0-N9XCM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K_VALUE = 10\n",
        "\n",
        "min_val = 1\n",
        "# On initialise les K representants de chaque classe\n",
        "K_mean = [255 * np.random.rand(32*32*3) for _ in range(10)]\n",
        "# Valeur précédente de ces representants\n",
        "K_save = [255 * np.random.rand(32*32*3) for _ in range(10)]\n",
        "\n",
        "def nearest_K(image):\n",
        "  \"\"\"\n",
        "  Retourne la classe K la plus proche de image\n",
        "  \"\"\"\n",
        "  min_d = None\n",
        "  min_k = None\n",
        "  for id_K, K_point in enumerate(K_mean):\n",
        "    d = np.linalg.norm(image - K_point)\n",
        "    if (min_d is None) or (d < min_d):\n",
        "      min_d = d\n",
        "      min_k = id_K\n",
        "  return min_k\n",
        "\n",
        "def mean_point(k, tab):\n",
        "  \"\"\"\n",
        "  Retourne barycentre des points (indicés) de tab\n",
        "  \"\"\"\n",
        "  if tab != []:\n",
        "    mean = 0\n",
        "    for id in tab:\n",
        "      mean += x_train[id] / len(tab)\n",
        "    K_mean[k] = mean\n",
        "    \n",
        "def stop_convergence():\n",
        "  \"\"\"\n",
        "  Evalue si l'on arrete les itérations\n",
        "  \"\"\"\n",
        "  for k in range(10):\n",
        "    if not(np.array_equal(K_mean[k], K_save[k])):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "#KMEAN\n",
        "iteration = 0\n",
        "while stop_convergence():\n",
        "  iteration += 1\n",
        "  K_nearest = [[] for _ in range(10)]\n",
        "  for id_image, image in enumerate(x_train):\n",
        "    K_nearest[nearest_K(image)].append(id_image)\n",
        "  for k in range(10):\n",
        "    K_save[k] = K_mean[k]\n",
        "    mean_point(k, K_nearest[k])\n",
        "  print(iteration)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BogFehmpI98t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "#TODO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}